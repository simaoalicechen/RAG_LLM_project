{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "KVNYo_amH5x6"
      },
      "outputs": [],
      "source": [
        "# %%bash\n",
        "\n",
        "# pip install --upgrade pip\n",
        "# pip install farm-haystack[colab,ocr,preprocessing,file-conversion,pdf]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from haystack.telemetry import tutorial_running\n",
        "\n",
        "tutorial_running(8)\n"
      ],
      "metadata": {
        "id": "FriwnabmIE-a"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "\n",
        "logging.basicConfig(format=\"%(levelname)s - %(name)s -  %(message)s\", level=logging.WARNING)\n",
        "logging.getLogger(\"haystack\").setLevel(logging.INFO)\n"
      ],
      "metadata": {
        "id": "NpEaoncJIYJ4"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from haystack.utils import fetch_archive_from_http\n",
        "\n",
        "\n",
        "# This fetches some sample files to work with\n",
        "doc_dir = \"data/tutorial8\"\n",
        "s3_url = \"https://s3.eu-central-1.amazonaws.com/deepset.ai-farm-qa/datasets/documents/preprocessing_tutorial8.zip\"\n",
        "fetch_archive_from_http(url=s3_url, output_dir=doc_dir)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1DCOyP-jIcbb",
        "outputId": "a4ba77f8-1653-44cc-e0b3-23a8cb29eaef"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:haystack.utils.import_utils:Fetching from https://s3.eu-central-1.amazonaws.com/deepset.ai-farm-qa/datasets/documents/preprocessing_tutorial8.zip to 'data/tutorial8'\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from haystack.nodes import TextConverter, PDFToTextConverter, DocxToTextConverter, PreProcessor\n",
        "\n",
        "\n",
        "converter = TextConverter(remove_numeric_tables=True, valid_languages=[\"en\"])\n",
        "doc_txt = converter.convert(file_path=\"data/tutorial8/classics.txt\", meta=None)[0]\n",
        "\n",
        "converter = PDFToTextConverter(remove_numeric_tables=True, valid_languages=[\"en\"])\n",
        "doc_pdf = converter.convert(file_path=\"data/tutorial8/bert.pdf\", meta=None)[0]\n",
        "\n",
        "converter = DocxToTextConverter(remove_numeric_tables=False, valid_languages=[\"en\"])\n",
        "doc_docx = converter.convert(file_path=\"data/tutorial8/heavy_metal.docx\", meta=None)[0]\n"
      ],
      "metadata": {
        "id": "SUE7e3pgIf0_"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from haystack.utils import convert_files_to_docs\n",
        "\n",
        "\n",
        "all_docs = convert_files_to_docs(dir_path=doc_dir)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-8mEhFU1IkwR",
        "outputId": "180f14f9-a1de-4b85-9d81-56c4d731c028"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:haystack.utils.preprocessing:Converting data/tutorial8/classics.txt\n",
            "INFO:haystack.utils.preprocessing:Converting data/tutorial8/bert.pdf\n",
            "INFO:haystack.utils.preprocessing:Converting data/tutorial8/heavy_metal.docx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from haystack.nodes import PreProcessor\n",
        "\n",
        "\n",
        "# This is a default usage of the PreProcessor.\n",
        "# Here, it performs cleaning of consecutive whitespaces\n",
        "# and splits a single large document into smaller documents.\n",
        "# Each document is up to 1000 words long and document breaks cannot fall in the middle of sentences\n",
        "# Note how the single document passed into the document gets split into 5 smaller documents\n",
        "\n",
        "preprocessor = PreProcessor(\n",
        "    clean_empty_lines=True,\n",
        "    clean_whitespace=True,\n",
        "    clean_header_footer=False,\n",
        "    split_by=\"word\",\n",
        "    split_length=100,\n",
        "    split_respect_sentence_boundary=True,\n",
        ")\n",
        "docs_default = preprocessor.process([doc_txt])\n",
        "print(f\"n_docs_input: 1\\nn_docs_output: {len(docs_default)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XA0rV2rWImhx",
        "outputId": "a8db951f-ed4d-48e9-c69d-f0ec1e7a3353"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "Preprocessing: 100%|██████████| 1/1 [00:00<00:00, 38.16docs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_docs_input: 1\n",
            "n_docs_output: 51\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Not respecting sentence boundary vs respecting sentence boundary\n",
        "\n",
        "preprocessor_nrsb = PreProcessor(split_respect_sentence_boundary=False)\n",
        "docs_nrsb = preprocessor_nrsb.process([doc_txt])\n",
        "\n",
        "print(\"RESPECTING SENTENCE BOUNDARY\")\n",
        "end_text = docs_default[0].content[-50:]\n",
        "print('End of document: \"...' + end_text + '\"')\n",
        "print()\n",
        "print(\"NOT RESPECTING SENTENCE BOUNDARY\")\n",
        "end_text_nrsb = docs_nrsb[0].content[-50:]\n",
        "print('End of document: \"...' + end_text_nrsb + '\"')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jE7b-EELIr_9",
        "outputId": "254e9025-8003-4bf1-ca0c-e4b7bce48362"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Preprocessing: 100%|██████████| 1/1 [00:00<00:00, 54.89docs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPECTING SENTENCE BOUNDARY\n",
            "End of document: \"...rnerstone of a typical elite European education.\n",
            "\n",
            "\"\n",
            "\n",
            "NOT RESPECTING SENTENCE BOUNDARY\n",
            "End of document: \"...xts used as part of a curriculum, both derive from\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sliding window approach\n",
        "\n",
        "preprocessor_sliding_window = PreProcessor(split_overlap=3, split_length=10, split_respect_sentence_boundary=False)\n",
        "docs_sliding_window = preprocessor_sliding_window.process([doc_txt])\n",
        "\n",
        "doc1 = docs_sliding_window[0].content[:200]\n",
        "doc2 = docs_sliding_window[1].content[:100]\n",
        "doc3 = docs_sliding_window[2].content[:100]\n",
        "\n",
        "print('Document 1: \"' + doc1 + '...\"')\n",
        "print('Document 2: \"' + doc2 + '...\"')\n",
        "print('Document 3: \"' + doc3 + '...\"')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9coDWkyCIwhu",
        "outputId": "6f8b1e04-e6ee-4087-ec05-b00fcd71aecc"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Preprocessing: 100%|██████████| 1/1 [00:00<00:00, 21.46docs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Document 1: \"Classics or classical studies is the study of classical antiquity,...\"\n",
            "Document 2: \"of classical antiquity, and in the Western world traditionally refers...\"\n",
            "Document 3: \"world traditionally refers to the study of Classical Greek and...\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_docs = convert_files_to_docs(dir_path=doc_dir)\n",
        "preprocessor = PreProcessor(\n",
        "    clean_empty_lines=True,\n",
        "    clean_whitespace=True,\n",
        "    clean_header_footer=False,\n",
        "    split_by=\"word\",\n",
        "    split_length=100,\n",
        "    split_respect_sentence_boundary=True,\n",
        ")\n",
        "docs = preprocessor.process(all_docs)\n",
        "\n",
        "print(f\"n_files_input: {len(all_docs)}\\nn_docs_output: {len(docs)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uPU1HiLAIzB2",
        "outputId": "363b840b-3fb6-4f67-8908-eecd0163840d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:haystack.utils.preprocessing:Converting data/tutorial8/classics.txt\n",
            "INFO:haystack.utils.preprocessing:Converting data/tutorial8/bert.pdf\n",
            "INFO:haystack.utils.preprocessing:Converting data/tutorial8/heavy_metal.docx\n",
            "Preprocessing:   0%|          | 0/3 [00:00<?, ?docs/s]WARNING:haystack.nodes.preprocessor.preprocessor:We found one or more sentences whose split count is higher than the split length.\n",
            "Preprocessing: 100%|██████████| 3/3 [00:00<00:00, 38.88docs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_files_input: 3\n",
            "n_docs_output: 175\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9ZMZiU0VI184"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}